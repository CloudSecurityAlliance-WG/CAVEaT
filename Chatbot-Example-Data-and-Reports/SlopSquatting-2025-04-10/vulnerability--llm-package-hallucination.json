{
  "type": "vulnerability",
  "spec_version": "2.1",
  "id": "vulnerability--llm-package-hallucination",
  "created": "2025-04-10T12:00:00.000Z",
  "modified": "2025-04-10T12:00:00.000Z",
  "name": "LLM Package Hallucination Vulnerability",
  "description": "This vulnerability stems from Large Language Models' (LLMs) tendency to hallucinate non-existent package names during code generation. Research has shown that LLMs generate fictitious package names at significant rates: commercial models average 5.2% hallucination rates, while open-source models average 21.7%. These hallucinations are often consistent and repeatable, with 58% of hallucinated packages reoccurring in subsequent generations, making them valuable targets for attackers. The vulnerability is exacerbated in cloud environments where development teams rely heavily on AI-assisted coding tools, DevOps automation, and rapid deployment pipelines, potentially allowing compromised packages to quickly propagate through cloud infrastructure and microservices.",
  "external_references": [
    {
      "source_name": "CAVEaT",
      "external_id": "CAVEaT-VUL-LLM-HALLUCINATION",
      "url": "https://github.com/cloudsecurityalliance/caveat"
    },
    {
      "source_name": "arXiv",
      "description": "We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs",
      "url": "https://arxiv.org/abs/2406.10279"
    }
  ]
}
